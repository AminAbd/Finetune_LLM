{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508895f2",
   "metadata": {},
   "source": [
    "# **Tokenizing text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1141b23",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**\n",
    "\n",
    "Import necessary libraries for data processing, dataset handling, and tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcc8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "from pprint import pprint\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f401c5f",
   "metadata": {},
   "source": [
    "## **Initialize Tokenizer**\n",
    "\n",
    "Load the tokenizer for the EleutherAI/pythia-70m model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef296a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21862b7",
   "metadata": {},
   "source": [
    "## **Example Text**\n",
    "\n",
    "Create a simple example text to demonstrate tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791b2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi, how are you?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f39494",
   "metadata": {},
   "source": [
    "## **Encode Text**\n",
    "\n",
    "Tokenize the example text and get the input IDs (token IDs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41547d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12764, 13, 849, 403, 368, 32]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer(text)[\"input_ids\"]\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ef60b",
   "metadata": {},
   "source": [
    "## **Decode Tokens**\n",
    "\n",
    "Convert the token IDs back to text to verify the tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff0acc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded tokens back into text:  Hi, how are you?\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(encoded_text)\n",
    "print(\"Decoded tokens back into text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd72bde",
   "metadata": {},
   "source": [
    "## **Tokenize Multiple Texts**\n",
    "\n",
    "Tokenize multiple texts at once to see how the tokenizer handles batch processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969eedde",
   "metadata": {},
   "source": [
    "# **Tokenize multiple texts at once**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d6d59",
   "metadata": {},
   "source": [
    "## **Apply Padding**\n",
    "\n",
    "Use padding to make all sequences the same length (padding tokens added to shorter sequences).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63005439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded several texts:  [[12764, 13, 849, 403, 368, 32], [42, 1353, 1175], [4374]]\n"
     ]
    }
   ],
   "source": [
    "list_texts = [\"Hi, how are you?\", \"I'm good\", \"Yes\"]\n",
    "encoded_texts = tokenizer(list_texts)\n",
    "print(\"Encoded several texts: \", encoded_texts[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73869b",
   "metadata": {},
   "source": [
    "## **Apply Truncation**\n",
    "\n",
    "Truncate sequences to a maximum length of 3 tokens (from the right side by default).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700ff6c",
   "metadata": {},
   "source": [
    "# **Padding and truncation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f05ad",
   "metadata": {},
   "source": [
    "## **Left-Side Truncation**\n",
    "\n",
    "Change truncation side to the left, so tokens are removed from the beginning of the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb458d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using padding:  [[12764, 13, 849, 403, 368, 32], [42, 1353, 1175, 0, 0, 0], [4374, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "encoded_texts_longest = tokenizer(list_texts, padding=True)\n",
    "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8842dd",
   "metadata": {},
   "source": [
    "## **Padding and Truncation Combined**\n",
    "\n",
    "Apply both padding and truncation together to handle variable-length sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4245fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using truncation:  [[12764, 13, 849], [42, 1353, 1175], [4374]]\n"
     ]
    }
   ],
   "source": [
    "encoded_texts_truncation = tokenizer(list_texts, max_length=3, truncation=True)\n",
    "print(\"Using truncation: \", encoded_texts_truncation[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a11a3",
   "metadata": {},
   "source": [
    "## **Display Dataset Information**\n",
    "\n",
    "Print the total number of examples and show the first 5 question-answer pairs from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50d7811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using left-side truncation:  [[403, 368, 32], [42, 1353, 1175], [4374]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.truncation_side = \"left\"\n",
    "encoded_texts_truncation_left = tokenizer(list_texts, max_length=3, truncation=True)\n",
    "print(\"Using left-side truncation: \", encoded_texts_truncation_left[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c083c",
   "metadata": {},
   "source": [
    "## **Determine Maximum Length**\n",
    "\n",
    "Calculate the maximum length to use for tokenization based on the actual sequence length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a36aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using both padding and truncation:  [[403, 368, 32], [42, 1353, 1175], [4374, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_texts_both = tokenizer(list_texts, max_length=3, truncation=True, padding=True)\n",
    "print(\"Using both padding and truncation: \", encoded_texts_both[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4457e",
   "metadata": {},
   "source": [
    "## **Apply Truncation with Max Length**\n",
    "\n",
    "Tokenize the text with truncation applied, using the calculated maximum length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4c986",
   "metadata": {},
   "source": [
    "# **Prepare instruction dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b7a33",
   "metadata": {},
   "source": [
    "## **View Tokenized Input IDs**\n",
    "\n",
    "Display the token IDs after truncation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa9f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2073aaa2e18c4471810c92934e4bf0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ameen\\Desktop\\GitHub\\Finetune_LLM\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ameen\\.cache\\huggingface\\hub\\datasets--kotzeje--lamini_docs.jsonl. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58757567a0d146dca7d568f25bb2e798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-6359aa989b6713(…):   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ecff70a8a64c759eac66a799295249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One datapoint in the finetuning dataset:\n",
      "{'answer': 'There are several metrics that can be used to evaluate the '\n",
      "           'performance and quality of generated text from Lamini models, '\n",
      "           'including perplexity, BLEU score, and human evaluation. Perplexity '\n",
      "           'measures how well the model predicts the next word in a sequence, '\n",
      "           'while BLEU score measures the similarity between the generated '\n",
      "           'text and a reference text. Human evaluation involves having human '\n",
      "           'judges rate the quality of the generated text based on factors '\n",
      "           'such as coherence, fluency, and relevance. It is recommended to '\n",
      "           'use a combination of these metrics for a comprehensive evaluation '\n",
      "           \"of the model's performance.\",\n",
      " 'question': '### Question:\\n'\n",
      "             'How can I evaluate the performance and quality of the generated '\n",
      "             'text from Lamini models?\\n'\n",
      "             '\\n'\n",
      "             '### Answer:'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset directly from Hugging Face (no manual download needed)\n",
    "dataset = load_dataset(\"kotzeje/lamini_docs.jsonl\")\n",
    "instruction_dataset_df = dataset[\"train\"].to_pandas()\n",
    "examples = instruction_dataset_df.to_dict()\n",
    "\n",
    "if \"question\" in examples and \"answer\" in examples:\n",
    "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "elif \"instruction\" in examples and \"response\" in examples:\n",
    "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
    "elif \"input\" in examples and \"output\" in examples:\n",
    "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "else:\n",
    "  text = examples[\"text\"][0]\n",
    "\n",
    "prompt_template = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\"\n",
    "\n",
    "num_examples = len(examples[\"question\"])\n",
    "finetuning_dataset = []\n",
    "for i in range(num_examples):\n",
    "  question = examples[\"question\"][i]\n",
    "  answer = examples[\"answer\"][i]\n",
    "  text_with_prompt_template = prompt_template.format(question=question)\n",
    "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"One datapoint in the finetuning dataset:\")\n",
    "pprint(finetuning_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0ce6a",
   "metadata": {},
   "source": [
    "## **Convert Dataset and Apply Tokenization**\n",
    "\n",
    "Convert the finetuning dataset list to a Hugging Face Dataset object and apply the tokenization function to all examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1447bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs/examples in the dataset: 1400\n",
      "\n",
      "First 5 examples from the dataset:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Question: How can I evaluate the performance and quality of the generated text from Lamini models?\n",
      "Answer: There are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Question: Can I find information about the code's approach to handling long-running tasks and background jobs?\n",
      "Answer: Yes, the code includes methods for submitting jobs, checking job status, and retrieving job results. It also includes a method for canceling jobs. Additionally, there is a method for sampling multiple outputs from a model, which could be useful for long-running tasks.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Question: How does Lamini AI handle requests for generating text that requires reasoning or decision-making based on given information?\n",
      "Answer: Lamini AI offers features for generating text that requires logical reasoning or inference beyond simple text generation. It can handle user prompts that involve complex reasoning or logical inference, and can generate text that captures the nuances of different cultural or regional variations.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Question: Does the `submit_job()` function expose any advanced training options such as learning rate schedules or early stopping?\n",
      "Answer: It is unclear which `submit_job()` function is being referred to as there is no such function defined in Lamini’s python library snippets. Please provide more information or context to answer the question accurately.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Question: Does the `add_data()` function support different data augmentation techniques or preprocessing options for training data?\n",
      "Answer: No, the `add_data()` function does not support different data augmentation techniques or preprocessing options for training data. It simply adds the provided examples to the program's list of examples.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print dataset information\n",
    "print(f\"Number of pairs/examples in the dataset: {len(instruction_dataset_df)}\")\n",
    "print(f\"\\nFirst 5 examples from the dataset:\\n\")\n",
    "print(\"=\"*80)\n",
    "for i in range(min(5, len(instruction_dataset_df))):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Question: {examples['question'][i]}\")\n",
    "    print(f\"Answer: {examples['answer'][i]}\")\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047d6c0",
   "metadata": {},
   "source": [
    "## **Add Labels Column**\n",
    "\n",
    "Add a labels column to the tokenized dataset (for training, labels are typically the same as input_ids).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c819d2ff",
   "metadata": {},
   "source": [
    "# **Tokenize a single example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18d596",
   "metadata": {},
   "source": [
    "## **Create Train/Test Split**\n",
    "\n",
    "Split the dataset into training and testing sets with a 90/10 ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e98edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4118 19782    27   187  2347   476   309  7472   253  3045   285  3290\n",
      "    273   253  4561  2505   432   418  4988    74  3210    32   187   187\n",
      "   4118 37741    27  2512   403  2067 17082   326   476   320   908   281\n",
      "   7472   253  3045   285  3290   273  4561  2505   432   418  4988    74\n",
      "   3210    13  1690 44229   414    13   378  1843    54  4868    13   285\n",
      "   1966  7103    15  3545 12813   414  5593   849   973   253  1566 26295\n",
      "    253  1735  3159   275   247  3425    13  1223   378  1843    54  4868\n",
      "   5593   253 14259   875   253  4561  2505   285   247  3806  2505    15\n",
      "   8801  7103  8687  1907  1966 16006  2281   253  3290   273   253  4561\n",
      "   2505  1754   327  2616   824   347 25253    13  2938  1371    13   285\n",
      "  17200    15   733   310  8521   281   897   247  5019   273   841 17082\n",
      "    323   247 11088  7103   273   253  1566   434  3045    15]]\n"
     ]
    }
   ],
   "source": [
    "text = finetuning_dataset[0][\"question\"] + finetuning_dataset[0][\"answer\"]\n",
    "tokenized_inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"np\",\n",
    "    padding=True\n",
    ")\n",
    "print(tokenized_inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bab834",
   "metadata": {},
   "source": [
    "## **Load Alternative Dataset**\n",
    "\n",
    "Load an alternative finetuning dataset from Hugging Face (lamini/lamini_docs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e19f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "max_length = min(\n",
    "    tokenized_inputs[\"input_ids\"].shape[1],\n",
    "    max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437b322",
   "metadata": {},
   "source": [
    "## **Define Additional Dataset Paths**\n",
    "\n",
    "Define paths to other available datasets that can be used for fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a87e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"np\",\n",
    "    truncation=True,\n",
    "    max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a01114",
   "metadata": {},
   "source": [
    "## **Load and Inspect Taylor Swift Dataset**\n",
    "\n",
    "Load the Taylor Swift dataset and display an example to see its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c6bb6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4118, 19782,    27,   187,  2347,   476,   309,  7472,   253,\n",
       "         3045,   285,  3290,   273,   253,  4561,  2505,   432,   418,\n",
       "         4988,    74,  3210,    32,   187,   187,  4118, 37741,    27,\n",
       "         2512,   403,  2067, 17082,   326,   476,   320,   908,   281,\n",
       "         7472,   253,  3045,   285,  3290,   273,  4561,  2505,   432,\n",
       "          418,  4988,    74,  3210,    13,  1690, 44229,   414,    13,\n",
       "          378,  1843,    54,  4868,    13,   285,  1966,  7103,    15,\n",
       "         3545, 12813,   414,  5593,   849,   973,   253,  1566, 26295,\n",
       "          253,  1735,  3159,   275,   247,  3425,    13,  1223,   378,\n",
       "         1843,    54,  4868,  5593,   253, 14259,   875,   253,  4561,\n",
       "         2505,   285,   247,  3806,  2505,    15,  8801,  7103,  8687,\n",
       "         1907,  1966, 16006,  2281,   253,  3290,   273,   253,  4561,\n",
       "         2505,  1754,   327,  2616,   824,   347, 25253,    13,  2938,\n",
       "         1371,    13,   285, 17200,    15,   733,   310,  8521,   281,\n",
       "          897,   247,  5019,   273,   841, 17082,   323,   247, 11088,\n",
       "         7103,   273,   253,  1566,   434,  3045,    15]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e1f21",
   "metadata": {},
   "source": [
    "# **Tokenize the instruction dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71cd52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    if \"question\" in examples and \"answer\" in examples:\n",
    "      text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "    elif \"input\" in examples and \"output\" in examples:\n",
    "      text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "    else:\n",
    "      text = examples[\"text\"][0]\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea31bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27687b3f826c44f49f74a4cafbe46097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1400\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convert the finetuning_dataset list to a Hugging Face Dataset object\n",
    "finetuning_dataset_loaded = datasets.Dataset.from_list(finetuning_dataset)\n",
    "\n",
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1a8de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58706f",
   "metadata": {},
   "source": [
    "# **Prepare test/train splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e56042c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4e811",
   "metadata": {},
   "source": [
    "## **Some datasets for you to try**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f997e96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8362422a52ec4c57ba99a5bb0e091b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ameen\\Desktop\\GitHub\\Finetune_LLM\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ameen\\.cache\\huggingface\\hub\\datasets--lamini--lamini_docs. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0f3713226547648468ae42e76a440b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-5cdebbc48da413(…):   0%|          | 0.00/615k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d333fb2dbcc84b188520fb5bce85bde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001-4c77a066a883f33(…):   0%|          | 0.00/83.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92aab3e34604cc386e1c9308210e34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6b43151b134600aaa61b2fa0fb60f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
    "finetuning_dataset = datasets.load_dataset(finetuning_dataset_path)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83b4411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "taylor_swift_dataset = \"lamini/taylor_swift\"\n",
    "bts_dataset = \"lamini/bts\"\n",
    "open_llms = \"lamini/open_llms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af114c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94146d40b0d479e8eadf63a1f6e462d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/573 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ameen\\Desktop\\GitHub\\Finetune_LLM\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ameen\\.cache\\huggingface\\hub\\datasets--lamini--taylor_swift. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a46010f9c0245139abc45113763e7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-54dd04266a81db(…):   0%|          | 0.00/257k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42209755a6c1411bb0a9d9db3ed72d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001-185d72ed4b72e46(…):   0%|          | 0.00/46.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e797a6a720414ea7b003b6f58d8228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/783 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5559a66712cd42e6bd685a48d9d36086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the most popular Taylor Swift song among millennials? How does this song relate to the millennial generation? What is the significance of this song in the millennial culture?', 'answer': 'Taylor Swift\\'s \"Shake It Off\" is the most popular song among millennials. This song relates to the millennial generation as it is an anthem of self-acceptance and embracing one\\'s individuality. The song\\'s message of not letting others bring you down and to just dance it off resonates with the millennial culture, which is often characterized by a strong sense of individuality and a rejection of societal norms. Additionally, the song\\'s upbeat and catchy melody makes it a perfect fit for the millennial generation, which is known for its love of pop music.', 'input_ids': [1276, 310, 253, 954, 4633, 11276, 24619, 4498, 2190, 24933, 8075, 32, 1359, 1057, 436, 4498, 14588, 281, 253, 24933, 451, 5978, 32, 1737, 310, 253, 8453, 273, 436, 4498, 275, 253, 24933, 451, 4466, 32, 37979, 24619, 434, 346, 2809, 640, 733, 5566, 3, 310, 253, 954, 4633, 4498, 2190, 24933, 8075, 15, 831, 4498, 7033, 281, 253, 24933, 451, 5978, 347, 352, 310, 271, 49689, 273, 1881, 14, 14764, 593, 285, 41859, 581, 434, 2060, 414, 15, 380, 4498, 434, 3935, 273, 417, 13872, 2571, 3324, 368, 1066, 285, 281, 816, 11012, 352, 745, 8146, 684, 342, 253, 24933, 451, 4466, 13, 534, 310, 2223, 7943, 407, 247, 2266, 3282, 273, 2060, 414, 285, 247, 18235, 273, 38058, 22429, 15, 9157, 13, 253, 4498, 434, 598, 19505, 285, 5834, 90, 40641, 2789, 352, 247, 3962, 4944, 323, 253, 24933, 451, 5978, 13, 534, 310, 1929, 323, 697, 2389, 273, 1684, 3440, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1276, 310, 253, 954, 4633, 11276, 24619, 4498, 2190, 24933, 8075, 32, 1359, 1057, 436, 4498, 14588, 281, 253, 24933, 451, 5978, 32, 1737, 310, 253, 8453, 273, 436, 4498, 275, 253, 24933, 451, 4466, 32, 37979, 24619, 434, 346, 2809, 640, 733, 5566, 3, 310, 253, 954, 4633, 4498, 2190, 24933, 8075, 15, 831, 4498, 7033, 281, 253, 24933, 451, 5978, 347, 352, 310, 271, 49689, 273, 1881, 14, 14764, 593, 285, 41859, 581, 434, 2060, 414, 15, 380, 4498, 434, 3935, 273, 417, 13872, 2571, 3324, 368, 1066, 285, 281, 816, 11012, 352, 745, 8146, 684, 342, 253, 24933, 451, 4466, 13, 534, 310, 2223, 7943, 407, 247, 2266, 3282, 273, 2060, 414, 285, 247, 18235, 273, 38058, 22429, 15, 9157, 13, 253, 4498, 434, 598, 19505, 285, 5834, 90, 40641, 2789, 352, 247, 3962, 4944, 323, 253, 24933, 451, 5978, 13, 534, 310, 1929, 323, 697, 2389, 273, 1684, 3440, 15]}\n"
     ]
    }
   ],
   "source": [
    "dataset_swiftie = datasets.load_dataset(taylor_swift_dataset)\n",
    "print(dataset_swiftie[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305b964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
